{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e82cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0.0: 500, 1.0: 268})\n",
      "LR: 0.772163 (0.047603)\n",
      "LDA: 0.766969 (0.047966)\n",
      "NB: 0.759142 (0.038960)\n",
      "RC: 0.770865 (0.050661)\n",
      "SVC: 0.756545 (0.056222)\n",
      "Random Forest: 0.763038 (0.044072)\n",
      "Extra Trees: 0.765567 (0.050294)\n",
      "Gradient Boosting: 0.733237 (0.084247)\n",
      "LR Accuracy using Grid Search  0.7721804511278195\n",
      "LR Best Parameters using Grid Search {'C': 1, 'solver': 'newton-cg'}\n",
      "LR Best Accuracy using Random Search 0.7734791524265209\n",
      "LR Best Parameters using Random Search {'C': 2.195254015709299, 'penalty': 'l1'}\n",
      "0.7913385826771654\n"
     ]
    }
   ],
   "source": [
    "#importing libraries and classes\n",
    "import pickle\n",
    "import numpy\n",
    "from pandas import read_csv\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Dataset used - Pima Indians onset of diabetes dataset\n",
    "url = 'https://goo.gl/bDdBiA'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = read_csv(url, names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "#Numerical Data is standardized using standard scaler\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "#Checking of the dataset is imbalanced\n",
    "print(Counter(Y))\n",
    "#Algorithm Evaluation\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('RC', RidgeClassifier()))\n",
    "models.append(('SVC', SVC()))\n",
    "#Below algorithms are bagging and boosting ensemble  methods to check if the performance of model is increased\n",
    "models.append(('Random Forest',RandomForestClassifier(n_estimators=100, max_features=3)))\n",
    "models.append(('Extra Trees',ExtraTreesClassifier(n_estimators=100, max_features=3)))\n",
    "models.append(('Gradient Boosting',GradientBoostingClassifier(n_estimators=100,learning_rate=0.5,max_features=3)))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
    "    cv_results = cross_val_score(model, rescaledX, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "\n",
    "#By seeing the results , it is evident to use Logistic regression algorithm as it has best accuracy\n",
    "##Now  we would improve the accuracy of the Logistic regression algorithm using grid search algorithm tuning methods\n",
    "CValues = numpy.array([1,10,2,3,4,5,6,7])\n",
    "param_grid = dict(C=CValues,solver=[\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"])\n",
    "grid = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid,cv=10)\n",
    "grid.fit(rescaledX, Y)\n",
    "print('LR Accuracy using Grid Search ', grid.best_score_)\n",
    "print('LR Best Parameters using Grid Search', grid.best_params_)\n",
    "    \n",
    "#Now  we would improve the accuracy of the Logistic regression algorithm using Random search algorithm tuning methods\n",
    "##Parameter C is sampled using unifrom sampling method from scipy.stats.distributions\n",
    "###Solver Saga and newton-cg has similar results in grid search, we are using solver saga as it can be tested with both L1 and L2 penalty.\n",
    "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2','l1'])\n",
    "random=RandomizedSearchCV(LogisticRegression(solver='saga',random_state=0), distributions, random_state=0,cv=10)\n",
    "random.fit(rescaledX, Y)\n",
    "print('LR Best Accuracy using Random Search', random.best_score_)\n",
    "print('LR Best Parameters using Random Search', random.best_params_)\n",
    "\n",
    "#Now  we will use tuning on ensemble algorithm  to check if the accuracy is increased\n",
    "distributions = dict(n_estimators=[50,60,70,80,90,100,110,120], max_features=[3,4,5,6,7,8])\n",
    "randomRF=RandomizedSearchCV(RandomForestClassifier(), distributions, random_state=0,cv=10)\n",
    "randomRF.fit(rescaledX, Y)\n",
    "print('Random Forest Best Accuracy using Random Search', randomRF.best_score_)\n",
    "print('Random Forest Best Parameters using Random Search', randomRF.best_params_)\n",
    "\n",
    "#After Seeing the results, we conclude to use the model logistic regresssion as it shows  best accuracy with C': 2.195254015709299, 'penalty': 'l1', and solver='Saga'\n",
    "##Let us save the model\n",
    "filename = 'finalized_model_Diabetes_Dataset.sav'\n",
    "#We have used the same parameters as we derived from hypertuning of algorithm parameters\n",
    "Final_model=LogisticRegression(solver='saga',random_state=0,C=2.1952,penalty='l1')\n",
    "Final_model.fit(rescaledX, Y)\n",
    "pickle.dump(Final_model, open(filename, 'wb'))\n",
    "\n",
    "#Load the model\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(rescaledX, Y, test_size=0.33,random_state=7)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
